# ğŸ“„ PDF Document Outline Extractor

## ğŸ“š Overview

This project implements a solution for **Round 1A: Understand Your Document Challenge** - a PDF outline extraction system that automatically identifies and extracts document structure including titles and hierarchical headings (H1, H2, H3) with their corresponding page numbers.

## ğŸ¯ Challenge Description

The goal is to build a machine-readable document structure extractor that:

- ğŸ“„ Processes PDF files up to 50 pages  
- ğŸ· Extracts document title and headings (H1, H2, H3)  
- ğŸ’¾ Outputs structured JSON with heading levels and page numbers  
- âš¡ Runs efficiently within strict performance constraints  

## ğŸš€ Our Approach

### ğŸ§© Methodology

Our solution employs a multi-layered approach to PDF structure extraction:

1. **Text Extraction**: Utilize robust PDF parsing libraries to extract text while preserving formatting information  
2. **Layout Analysis**: Analyze font sizes, styles, positioning, and whitespace patterns to identify heading candidates  
3. **Hierarchy Detection**: Implement Random Forest classifier to determine heading levels based on multiple factors beyond just font size  
4. **Context Validation**: Apply contextual rules to validate and refine heading classifications  

### âœ¨ Key Features

- ğŸ”¤ **Font-agnostic Detection**: Does not rely solely on font sizes for heading identification  
- ğŸ” **Multi-factor Analysis**: Considers position, styling, spacing, and content patterns  
- ğŸ›  **Robust Parsing**: Handles various PDF formats and layouts  
- â± **Performance Optimized**: Designed for sub-10-second execution on 50-page documents  
- ğŸŒ **Multilingual Support**: Capable of processing documents in multiple languages and various character encodings, ensuring broad applicability across diverse document sets. 

## ğŸ§° Technology Stack

### Core Libraries

- **PDF Processing**: [Specify your PDF library - e.g., PyMuPDF, pdfplumber, etc.]  
- **Text Analysis**: [Specify libraries used for text processing]  
- **Layout Detection**: [Specify any computer vision or layout analysis tools]  

### ğŸ¤– Machine Learning Model

- **Final Model**: **Random Forest Classifier**  
- ğŸ“¦ **Model Size**: < 200MB (compliant with constraints)  
- ğŸ› **Architecture**: Ensemble-based classification for heading level detection  
- ğŸ”Œ **Offline Operation**: All models bundled within container  

## ğŸ›  Development Challenges & Problems Faced

During the development process, we encountered several significant challenges that required iterative solutions and model improvements:

### 1. Decision Tree Classification Issues

**Problem**: Our initial implementation using decision tree models showed promising overall accuracy, but suffered from systematic confusion between H1 and H2 heading levels.

**Impact**:

- âœ”ï¸ Correct identification of headings but incorrect hierarchy assignment  
- ğŸ”„ Resulted in flattened or inverted document structure  
- âŒ Affected downstream processing and JSON output quality  

**Solution**: Enhanced feature engineering and eventually migrated to Random Forest to leverage ensemble learning for better hierarchy discrimination.

### 2. Model Evolution: Decision Tree â†’ Random Forest

**Problem**: Single decision tree models were prone to overfitting and couldn't capture the complex relationships between different heading features.

**Impact**:  

- â— Inconsistent performance across different PDF types  
- ğŸš« Poor generalization to unseen document formats  

**Solution**: **Implemented Random Forest classifier as our final model**, which provided:

- ğŸ”— Better handling of feature interactions  
- ğŸ›¡ Improved robustness against overfitting  
- ğŸ¯ Enhanced accuracy in distinguishing between H1, H2, and H3 levels  
- ğŸ“ˆ More stable performance across diverse document types  

### 3. Title Extraction from Metadata

**Problem**: The title extraction mechanism was pulling information from PDF metadata rather than analyzing the actual document content.

**Impact**:  

- ğŸ“› Extracted titles were often generic, unrelated, or missing entirely  
- âŒ No correlation between extracted title and actual document content  
- ğŸ˜• Failed to identify dynamically generated or embedded titles  

**Solution**: Implemented **content-based title detection** by analyzing the first page layout, font hierarchies, and positioning patterns.

### 4. False Positive Heading Detection

**Problem**: Bold body text and emphasized content were being incorrectly classified as headings.

**Impact**:

- â• Inflated heading counts in output JSON  
- ğŸ”„ Incorrect document structure representation  
- ğŸ“‰ Reduced precision in heading detection  

**Solution**: Added contextual validation rules and trained the Random Forest model with negative examples including:

- ğŸš¦ Minimum/maximum heading length thresholds  
- ğŸ“ Positional constraints (e.g., not mid-paragraph)  
- ğŸ” Content pattern analysis (avoiding inline emphasis)

### 5. DistilBERT Integration Issues

**Problem**: When attempting to use DistilBERT for semantic heading classification, the punkt tokenizer library caused significant compatibility and performance issues.

**Impact**:

- ğŸš« Tokenization failures on certain PDF text extractions  
- ğŸ¢ Increased processing time beyond acceptable limits  
- ğŸ”„ Dependency conflicts in containerized environment  

**Solution**:

- âŒ Abandoned the DistilBERT approach due to complexity and performance constraints  
- ğŸ”„ Switched to Random Forest with carefully engineered features  
- ğŸ›¡ Implemented fallback mechanisms for problematic text segments  
- âš™ï¸ Optimized model loading and inference pipeline  

### 6. Performance vs. Accuracy Trade-offs

**Problem**: Balancing the sophisticated analysis required for accurate heading detection with the strict 10-second execution time constraint.

**Impact**:

- ğŸ•° Initial implementations exceeded time limits  
- âš–ï¸ Had to compromise on some advanced features  

**Solution**: Random Forest provided an optimal balance of accuracy and speed, enabling comprehensive feature analysis within time constraints.

## Project Structure


```
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ process_pdfs.py
â””â”€â”€  Model_randomforest.pkl

```

0
## Installation \& Usage

### Building the Docker Image

```bash
docker build --platform linux/amd64 -t pdf-outline-extractor:latest .
```


### Running the Solution

```bash
docker run --rm \
  -v $(pwd)/input:/app/input \
  -v $(pwd)/output:/app/output \
  --network none \
  pdf-outline-extractor:latest
```


### Input/Output Format

**Input**: PDF files in `/app/input` directory

**Output**: JSON files in `/app/output` directory with format:

```json
{
  "title": "Document Title",
  "outline": [
    {
      "level": "H1",
      "text": "Chapter 1: Introduction",
      "page": 1
    },
    {
      "level": "H2", 
      "text": "Background",
      "page": 2
    },
    {
      "level": "H3",
      "text": "Historical Context",
      "page": 3
    }
  ]
}
```



## ğŸ“Š Performance Specifications

| Metric          | Specification                 | Our Performance         |
|-----------------|------------------------------|------------------------|
| â± Execution Time | â‰¤ 10 seconds (50-page PDF)    | [Your actual performance] |
| ğŸ“¦ Model Size    | â‰¤ 200MB                      | [Your model size]      |
| âš™ï¸ Architecture | AMD64 CPU only                | âœ… Compliant            |
| ğŸ’¾ Memory       | 16GB RAM available            | [Your memory usage]    |
| ğŸŒ Network      | Offline operation             | âœ… No network calls    |

## ğŸ§  Algorithm Details

### Random Forest Heading Classification

1. ğŸ“ **Text Extraction with Formatting**: Extract text while preserving font information, positioning, and styling  
2. âš™ï¸ **Feature Engineering**: Calculate comprehensive features for Random Forest input:  
    - ğŸ”  Font size relative to document average  
    - ğŸ…±ï¸ Bold/italic styling indicators  
    - ğŸ“ Position on page (top, middle, bottom)  
    - â†”ï¸ Whitespace before/after ratios  
    - ğŸ”¡ Line length and capitalization patterns  
    - ğŸ“Š Text density and character count  
    - â†ªï¸ Indentation levels  
3. ğŸŒ³ **Random Forest Classification**: Multi-class classification (Title/H1/H2/H3/Body) using ensemble of decision trees  
4. ğŸ” **Hierarchy Validation**: Post-processing to ensure logical heading hierarchy and resolve conflicts  

### Model Training Features

The Random Forest model was trained on the following key features:

- âœï¸ **Typography Features**: Font size, weight, style  
- ğŸ“ **Layout Features**: Position, spacing, alignment  
- ğŸ§¾ **Content Features**: Text length, capitalization, punctuation  
- ğŸ **Context Features**: Surrounding text properties, page location  

### Special Considerations

- ğŸŒ **Multi-language Support**: Handles various character encodings and languages  
- ğŸ“ **Complex Layouts**: Robust against multi-column layouts, tables, and graphics  
- ğŸš§ **Edge Cases**: Handles PDFs with inconsistent formatting or missing structure  

## âœ… Testing & Validation

The Random Forest solution has been tested on:

- ğŸ§‘ğŸ“ Simple academic papers  
- ğŸ›  Complex technical documents  
- ğŸŒ Multi-language documents  
- ğŸ–¨ Various PDF generators and formats  

## âš ï¸ Known Limitations

- ğŸ“‰ Model performance depends on training data diversity  
- ğŸ”„ May require retraining for highly specialized document types  
- âš ï¸ Feature extraction sensitive to PDF generation quality  

## ğŸ”® Future Enhancements (Round 1B Preparation)

This modular design enables easy extension for:

- ğŸ§  Enhanced semantic understanding  
- ğŸ“ Content summarization  
- ğŸ”— Cross-document relationship detection  
- ğŸŒ Advanced multilingual processing  
- ğŸ¯ Model fine-tuning for specific document domains  

## ğŸ’¡ Development Notes

### Model Training

- ğŸŒ³ Random Forest trained on diverse PDF corpus  
- ğŸ” Cross-validation used for hyperparameter tuning  
- ğŸ“Š Feature importance analysis guided feature selection  

### Debugging

- ğŸ”„ Add `--volume` mount for logs if needed during development  
- âš™ï¸ Use environment variables for configuration in development  
- ğŸ“‰ Model prediction confidence scores available for debugging  

### Optimization Techniques

- âš¡ Efficient feature extraction pipeline  
- ğŸ“¦ Model compression for size constraints  
- ğŸ¤¹â€â™‚ï¸ Parallel processing where applicable  

## ğŸ›¡ Compliance Checklist

- âœ… AMD64 architecture compatibility  
- âœ… No GPU dependencies  
- âœ… Model size â‰¤ 200MB  
- âœ… Offline operation (no network calls)  
- âœ… Execution time â‰¤ 10 seconds for 50-page PDF  
- âœ… Proper Docker volume mounting  
- âœ… JSON output format compliance  

---
